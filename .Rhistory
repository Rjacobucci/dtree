birthwt2$low <- as.factor(birthwt2$low)
names(birthwt2)[1] <- "y"
birthwt2$ptl<- as.factor(birthwt2$ptl)
birthwt2$ht <- as.factor(birthwt2$ht)
birthwt2$ui <- as.factor(birthwt2$ui)
birthwt2$ftv <- as.factor(birthwt2$ftv)
levels(birthwt2$y) <- c("low","high")
######
biopsy2 <- biopsy[complete.cases(biopsy),-c(1)]
names(biopsy2)[10] <- "y"
#levels(biopsy2$y) <- c("1","2")
######
names(College)[2] <- "y" #Apps
College2 <- College[,-c(11:17)]
#####
names(quine)[5] <- "y"
#####
names(Pima.tr)[8] <- "y"
#####
OME2 <- OME[,-1]
OME2$y <- OME2$Correct/OME2$Trials
OME3 <- OME2[,-c(5:6)]
#####
nlschools2 <- nlschools[1:1000,-3]
names(nlschools2)[1] <- "y"
str(nlschools2)
#####
names(minn38)[2] <- "y"
minn382 <- minn38[,-5]
levels(minn382$y) <- c("C","N","N","N")
#####
names(swiss)[1] <- "y" #fertility
######
names(Default)[1] <- "y"
Default2 <- Default[1:2000,]
#####
library(caret)
data(Sacramento)
str(Sacramento)
names(Sacramento)[7] <- "y"
Sacramento2 <- Sacramento[,-c(1,2,8:9)]
Sacramento2$y <- round(Sacramento2$y,-4)
Sacramento2$sqft <- round(Sacramento2$sqft,-2)
############ data
library(beepr)
dat.list <- list(HS,FB2,bfi2,crabs2,eb2,Wage2,cats,Cars932,Boston,
birthwt2,biopsy2,College,quine,Pima.tr,OME3,nlschools2,minn382,
swiss,Default2,Sacramento2)
# problems with nlschools, error with minn382
res.out <- list()
# problem with the third dataset
for(i in 1:20){
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("rpart"),n.rep=5,
samp.method="cv",tuneLength=15,stablelearner=FALSE,parallel=FALSE)
print(i)
}
res.out
?stable
# problem with the third dataset
for(i in 1:20){
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("rpart"),n.rep=5,
samp.method="cv",tuneLength=15,parallel=TRUE)
print(i)
}
res.out
res.out <- list()
# problem with the third dataset
for(i in 1:20){
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("rpart","ctreePrune"),n.rep=1,
samp.method="cv",tuneLength=15,parallel=TRUE)
print(i)
}
?stable
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("rpart","ctree"),n.rep=1,
samp.method="cv",tuneLength=15,parallel=TRUE)
traceback()
res.out <- list()
# problem with the third dataset
for(i in 1:20){
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("rpart","ctree"),n.rep=1,
samp.method="cv",tuneLength=15,parallel=FALSE)
print(i)
}
res.out <- list()
# problem with the third dataset
for(i in 1:20){
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("ctree"),n.rep=1,
samp.method="cv",tuneLength=1,parallel=FALSE)
print(i)
}
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("evtree"),n.rep=1,
samp.method="cv",tuneLength=1,parallel=FALSE)
?simplify2array
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("rpart"),n.rep=1,
samp.method="cv",tuneLength=1,parallel=FALSE)
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("rpart"),n.rep=2,
samp.method="cv",tuneLength=1,parallel=FALSE)
res.out <- list()
# problem with the third dataset
for(i in 1:20){
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("rpart","ctreePrune"),n.rep=2,
samp.method="cv",tuneLength=1,parallel=FALSE)
print(i)
}
?stable
?dtree
res.out <- list()
# problem with the third dataset
for(i in 1:20){
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("rpart","ctreePrune","ctree","bump","ctreePrune"),n.rep=2,
samp.method="cv",tuneLength=1,parallel=FALSE)
print(i)
}
res.out <- list()
# problem with the third dataset
for(i in 1:20){
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("rpart","ctreePrune","ctree","evtree"),n.rep=2,
samp.method="cv",tuneLength=1,parallel=FALSE)
print(i)
}
?stable
library(dtree)
i
i=4
res.out[[i]] <- stable(y~., dat.list[[i]],methods=c("rpart","ctreePrune","ctree","evtree"),n.rep=2,
samp.method="cv",tuneLength=c(15,1,2,3))
ctreePrune <- function(formula,data,qstar=0.05,sizeSatu=0.999)  {
#argum<-list(formula=medv~., data=Boston)
#argum <- list()
#####################################################
#####   changes parameters to grow a very large tree
#####################################################
ctrl <- ctree_control(mincriterion=1-sizeSatu)
#############################
### Grows a very large tree
#############################
#satTree <- do.call(partykit::ctree,argum)
satTree <- partykit::ctree(formula=formula, data=data,control=ctrl)
############################################################
#####  Collect relevant information about the saturated tree
#############################################################
satTreeInfo <- DFtreeInfo(satTree)
##############################
### Prune the saturated tree
##############################
temp <- fdrprune(satTree,qstar)
pruTree <- temp$tree
############################################################
#####  Collect relevant information about the pruned tree
#############################################################
pruTreeInfo <- temp$info
list(tree=pruTree,
info=pruTreeInfo,
qstar=qstar,
sizeSatu=sizeSatu,
pvalue=temp$pvalue
)
}
#################################################
###
### Function to obtain a pruned tree using FDR
###
### fit: object of class party
###
#################################################
fdrprune <- function(fit,qstar=0.05){
###################################################
#####  Collect relevant information about the tree
###################################################
datNo<-DFtreeInfo(fit)
############################################
#####  Select the nodes to prune starting
#####   from the bottom
############################################
############################
#### List of terminal nodes
############################
TNlist <- nodeids(fit,terminal=TRUE)
############################
#### List of non-terminal nodes
############################
wher <- nodeids(fit)%in%TNlist
nonTNlist <- nodeids(fit)[!wher]
##############################
####  Calculate pvalue for FDR
##############################
pval<-datNo$pvalue
pval<-pval[!is.na(pval)]
pval<-sort(pval)
m<-length(pval)
qstar<-qstar #### FDR is controlled at qstar*100%
i<-1:m
temp <- (i/m)*qstar
k<-sum(pval <= temp )
if (!k==0) pvalue<-temp[k] else pvalue<-0
#######################################
#### New alpha to declare significance
#######################################
alpha<-pvalue
######################################
#####  Identifies what nodes contain
#####  FDR corrected significant
#####  p-values
######################################
datNo$FDRsigYN<-datNo$pvalue <= alpha & !is.na(datNo$pvalue)
wher <- is.na(datNo$pvalue)
datNo$FDRsigYN[wher]<-NA
####################################
#### Identifies what nodes to prune
####################################
#### loop over all terminal nodes
for (i in TNlist) {
j<-i
#### repeat while parent pvalue is not significant
while ( (is.na(datNo$pvalue[j]) | datNo$pvalue[j] > alpha) & !datNo$node[j]==1 ) {
datNo$pruneYN[j]<-TRUE
j <- datNo$parent[j]
}
}
############################################################
##### Make sure that all the nodes above a significant node
#####   are non terminal
############################################################
#### List of nodes with significant pvalues
nonTNlist<-datNo$node [ !datNo$pruneYN ]
#### loop over all terminal nodes
for (i in nonTNlist) {
j<-i
#### repeat while parent pvalue is not significant
while ( !datNo$node[j]==1 ) {
datNo$pruneYN[j]<-FALSE
j <- datNo$parent[j]
}
}
##########################################
#### If all the nodes have to be pruned
#### except root node, but root node is
#### not significant then prune also root
##########################################
wher <- datNo$node==1
if (dim(datNo)[1]==1) {
datNo$pruneYN[wher]<-TRUE
} else if ( all(datNo$pruneYN[!wher]) & datNo$pvalue[wher]> alpha ) {
datNo$pruneYN[wher]<-TRUE
}
########################
#####  prune the tree
########################
nodesPru<-datNo$node[datNo$pruneYN]
out <- nodeprune(fit,nodesPru)
list(tree=out,info=datNo,pvalue=alpha)
}
##############################################################################
### This function collect information about nodes for trees grown using Ctree
##############################################################################
DFtreeInfo<-function(fit) {
############################################
### Calculates IDs and left and right nodes
############################################
#library(partykit)
nid <- nodeids(fit)
datNo <- nodeapply(fit, ids=nid, function(n) {
#
if (is.null(kids_node(n))) {
out <- data.frame(node= nodeids(n)[1],
left=NA,
right=NA)
}
if (!is.null(kids_node(n))) {
out <- data.frame(node= nodeids(n)[1],
left=nodeids(kids_node(n)[[1]])[1],
right=nodeids(kids_node(n)[[2]])[1])
}
out
})
datNo <- do.call("rbind",datNo)
#########################################
### Calculates the name of the covariates
### used in each split
#########################################
datNo$varName <- NA
if (!length(fit)==0) {
tmpNames <- names(data_party(fit))
temp<-nodeapply(fit,nid, FUN = function(n) {
tmp <- n$split$varid
tmpNames[tmp]
})
temp<-unlist(temp)
wher <- datNo$node %in% as.numeric(names(temp))
datNo$varName[wher]<-temp
}
###############################
### extract pvalues from nodes
###############################
if (!dim(datNo)[1]==1) {
temp<-nodeapply(fit, ids = nodeids(fit), function(n) info_node(n)$p.value)
pvalues<-sapply(1:length(temp),function(i){
if (is.null(temp[[i]])) out<-NA else out<-as.numeric(temp[[i]])
})
datNo$pvalue<-pvalues
}
if (dim(datNo)[1]==1) {
datNo$pvalue<-NA
}
###############################
### Defines terminal nodes
###############################
temp<-nodeids(fit,terminal=TRUE)
wher <- datNo$node %in% temp
datNo$terminal[wher]<-TRUE
datNo$terminal[!wher]<-FALSE
###############################
### Defines pruneYN column
###############################
datNo$pruneYN<-FALSE
###############################
### Defines FDRsigYN column
###############################
datNo$FDRsigYN<-NA
##########################################
#### Calculates identity of parent nodes
##########################################
datNo$parent<-NA
for (i in datNo$node) {
tmpil<-datNo$left[i]
tmpir<-datNo$right[i]
datNo$parent[tmpil]<-i
datNo$parent[tmpir]<-i
}
datNo
}
formula=y~.
data=dat.list[[i]]
possible.tune <- c(.05,.01,.001)
tune.ctreePrune=3
data.train=data
possible.tune <- c(.05,.01,.001)
tune <- possible.tune[1:tune.ctreePrune]
for(i in 1:length(tune.ctreePrune)){
out <- ctreePrune(formula=formula, data=data.train,qstar=tune[i])
}
out.list <- list()
out.list <- list()
for(i in 1:length(tune.ctreePrune)){
out.list[[i]] <- ctreePrune(formula=formula, data=data.train,qstar=tune[i])
}
out.list
length(tune.ctreePrune)
for(i in 1:tune.ctreePrune){
out.list[[i]] <- ctreePrune(formula=formula, data=data.train,qstar=tune[i])
}
out.list
for(i in 1:tune.ctreePrune){
met1 <- rep(NA,20)
met2 <- rep(NA,20)
for(i in 1:20){
set.seed(i)
ids1 <- sample(nrow(data.train),nrow(data.train),replace=TRUE)
train <- data.train[ids1,]
test <- data.train[-ids1,]
tt <- ctreePrune(formula=formula, data=train,qstar=tune[i])
if(class.response == "numeric" | class.response == "integer"){
met1[i] <- sqrt(mean((test[,response] - predict(tt$tree,test))^2))
pp = predict(tt$tree,test)
if(sd(pp)==0) pp <- pp+rnorm(length(pp),0,.000001)
met2[i] <- (cor(test[,response],pp))**2
}else{
if(all(duplicated(test[,response])[-1L])){
met1[i] <- NA
}else{
if(length(levels(class.response)) == 2){
met1[i] <- pROC::auc(test[,response],predict(tt$tree,test,type="prob")[,1])
}
}
met2[i] <- caret::confusionMatrix(test[,response],predict(tt$tree,test))$overall["Accuracy"]
}
}
print(met1);print(met2)
}
class.response="numeric"
for(i in 1:tune.ctreePrune){
met1 <- rep(NA,20)
met2 <- rep(NA,20)
for(i in 1:20){
set.seed(i)
ids1 <- sample(nrow(data.train),nrow(data.train),replace=TRUE)
train <- data.train[ids1,]
test <- data.train[-ids1,]
tt <- ctreePrune(formula=formula, data=train,qstar=tune[i])
if(class.response == "numeric" | class.response == "integer"){
met1[i] <- sqrt(mean((test[,response] - predict(tt$tree,test))^2))
pp = predict(tt$tree,test)
if(sd(pp)==0) pp <- pp+rnorm(length(pp),0,.000001)
met2[i] <- (cor(test[,response],pp))**2
}else{
if(all(duplicated(test[,response])[-1L])){
met1[i] <- NA
}else{
if(length(levels(class.response)) == 2){
met1[i] <- pROC::auc(test[,response],predict(tt$tree,test,type="prob")[,1])
}
}
met2[i] <- caret::confusionMatrix(test[,response],predict(tt$tree,test))$overall["Accuracy"]
}
}
print(met1);print(met2)
}
met1 <- rep(NA,20)
met2 <- rep(NA,20)
set.seed(i)
ids1 <- sample(nrow(data.train),nrow(data.train),replace=TRUE)
train <- data.train[ids1,]
test <- data.train[-ids1,]
tt <- ctreePrune(formula=formula, data=train,qstar=tune[j])
j=1
tt <- ctreePrune(formula=formula, data=train,qstar=tune[j])
if(class.response == "numeric" | class.response == "integer"){
met1[i] <- sqrt(mean((test[,response] - predict(tt$tree,test))^2))
pp = predict(tt$tree,test)
if(sd(pp)==0) pp <- pp+rnorm(length(pp),0,.000001)
met2[i] <- (cor(test[,response],pp))**2
}else{
if(all(duplicated(test[,response])[-1L])){
met1[i] <- NA
}else{
if(length(levels(class.response)) == 2){
met1[i] <- pROC::auc(test[,response],predict(tt$tree,test,type="prob")[,1])
}
}
met2[i] <- caret::confusionMatrix(test[,response],predict(tt$tree,test))$overall["Accuracy"]
}
class.response
head(data.train)
class.response="categorical"
for(j in 1:tune.ctreePrune){
met1 <- rep(NA,20)
met2 <- rep(NA,20)
for(i in 1:20){
set.seed(i)
ids1 <- sample(nrow(data.train),nrow(data.train),replace=TRUE)
train <- data.train[ids1,]
test <- data.train[-ids1,]
tt <- ctreePrune(formula=formula, data=train,qstar=tune[j])
if(class.response == "numeric" | class.response == "integer"){
met1[i] <- sqrt(mean((test[,response] - predict(tt$tree,test))^2))
pp = predict(tt$tree,test)
if(sd(pp)==0) pp <- pp+rnorm(length(pp),0,.000001)
met2[i] <- (cor(test[,response],pp))**2
}else{
if(all(duplicated(test[,response])[-1L])){
met1[i] <- NA
}else{
if(length(levels(class.response)) == 2){
met1[i] <- pROC::auc(test[,response],predict(tt$tree,test,type="prob")[,1])
}
}
met2[i] <- caret::confusionMatrix(test[,response],predict(tt$tree,test))$overall["Accuracy"]
}
}
print(met1);print(met2)
}
class.response
if(class.response == "numeric" | class.response == "integer"){
met1[i] <- sqrt(mean((test[,response] - predict(tt$tree,test))^2))
pp = predict(tt$tree,test)
if(sd(pp)==0) pp <- pp+rnorm(length(pp),0,.000001)
met2[i] <- (cor(test[,response],pp))**2
}else{
if(all(duplicated(test[,response])[-1L])){
met1[i] <- NA
}else{
if(length(levels(class.response)) == 2){
met1[i] <- pROC::auc(test[,response],predict(tt$tree,test,type="prob")[,1])
}
}
met2[i] <- caret::confusionMatrix(test[,response],predict(tt$tree,test))$overall["Accuracy"]
}
response
library(dtree)
library(dtree)
# continuous outcome
library(MASS) # for boston data
data(Boston)
out <- dtree(medv ~., data=Boston,methods=c("ctreePrune"),tuneLength=2)
traceback()
library(dtree)
out <- dtree(medv ~., data=Boston,methods=c("ctreePrune"),tuneLength=2)
library(dtree)
out <- dtree(medv ~., data=Boston,methods=c("ctreePrune"),tuneLength=2)
library(dtree)
out <- dtree(medv ~., data=Boston,methods=c("ctreePrune"),tuneLength=2)
library(dtree)
out <- dtree(medv ~., data=Boston,methods=c("ctreePrune"),tuneLength=2)
library(dtree)
out <- dtree(medv ~., data=Boston,methods=c("ctreePrune"),tuneLength=2)
library(dtree)
out <- dtree(medv ~., data=Boston,methods=c("ctreePrune"),tuneLength=2)
summary(out)
out <- dtree(default ~ ., data=Default,methods=c("lm","rpart","ctreePrune"))
# categorical outcome
library(ISLR)
data(Default)
out <- dtree(default ~ ., data=Default,methods=c("lm","rpart","ctreePrune"))
summary(out)
library(dtree)
library(dtree)
install.packages("tree")
data(Boston)
stab.out <- stable(formula=medv ~.,data=Boston,
methods=c("rpart","ctreePrune"),samp.method="cv",
tuneLength=2, n.rep=5, parallel=TRUE)
stab.out
