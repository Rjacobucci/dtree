{
    "collab_server" : "",
    "contents" : "#' Main function to calculate stability coefficients\n#'\n#' @param formula a formula, weight a response to left of ~.\n#' @param data Data frame to run models on\n#' @param methods Which tree methods to use. Defaults:\n#'        lm, rpart, tree, ctree, evtree. Also can use \"rf\" for random forests\n#' @param samp.method Sampling method. Refer to caret package trainControl()\n#'        documentation. Default is repeated cross-validation. Other options\n#'        include \"cv\" and \"boot\".\n#' @param tuneLength Number of tuning parameters to try. Applies to train()\n#' @param n.rep Number of times to replicate each method\n#' @param stablelearner Whether or not to use the stablelearner package to\n#'        calculate stability\n#' @param subset Whether to subset\n#' @param perc.sub What fraction of data to put into train dataset. 1-frac.sub\n#'        is allocated to test dataset. Defaults to 0.75\n#' @param weights Optional weights for each case.\n#' @param verbose\n#'\n#'\n#'\n#' @export\n\n\n\nstable = function(formula,\n                 data,\n                 methods=c(\"lm\",\"rpart\",\"tree\",\"ctree\",\"evtree\"),\n                 samp.method=\"repeatedcv\",\n                 tuneLength=3,\n                 n.rep=100,\n                 stablelearner=FALSE,\n                 subset=FALSE,\n                 perc.sub=.75,\n                 weights=NULL,\n                 verbose=FALSE){\n\n  res <- list()\n  out <- list()\n  out2 <- list()\n\n  if(stablelearner==FALSE){\n    for(i in 1:n.rep){\n      set.seed(i)\n      print(i)\n      ids <- sample(nrow(data),nrow(data),replace=TRUE)\n      out[[i]] <- dtree(formula,data[ids,],methods,samp.method,\n                        tuneLength,subset,perc.sub,prune,weights,verbose)\n\n      out2[[i]] <- out[[i]]$return.matrix\n    }\n    ret <- array(NA, dim=c(n.rep,length(methods),ncol(out2[[1]])))\n\n    for(j in 1:n.rep){\n      ret[j,,] <- out2[[j]]\n    }\n\n    ret.mean <- apply(ret,3,colMeans,na.rm=TRUE)\n    ret.var <- apply(ret,3,matrixStats::colVars,na.rm=TRUE)\n\n    ret.mean <- matrix(ret.mean,length(methods),7)\n    ret.var <- matrix(ret.var,length(methods),7)\n\n    row.names(ret.mean) <- methods\n    row.names(ret.var) <- methods\n\n    colnames(ret.mean) <- colnames(out2[[i]])\n    colnames(ret.var) <- colnames(out2[[i]])\n\n\n    tt = terms(x=formula,data=data)\n    preds <- attr(tt,\"term.labels\")\n\n    counts.mean <- matrix(NA,length(methods),length(preds))\n    counts.var <- matrix(NA,length(methods),length(preds))\n    rownames(counts.mean) <- rownames(counts.var) <- methods\n    colnames(counts.mean) <- colnames(counts.var) <- preds\n\n\n\n\n    if(any(methods==c(\"ctree\"))){\n      var.count <- matrix(NA,n.rep,length(preds))\n      colnames(var.count) <- preds\n      where.ctree <- list()\n      for(i in 1:n.rep){\n        hh <- out[[i]]$ctree.splits\n        tab <- table(hh[,1])\n        where.ctree[[i]] <- hh\n\n        for(j in 1:length(preds)){\n          var.count[i,preds[j]] <- tab[preds[j]]\n          if(is.na(var.count[i,preds[j]]==TRUE)) var.count[i,preds[j]] <- 0\n        }\n      }\n\n      counts.mean[\"ctree\",] <- colMeans(var.count)\n      counts.var[\"ctree\",] <- round(matrixStats::colVars(var.count),2)\n      nn <- plyr::ldply(where.ctree)\n      if(length(unique(nn[,1])) == 1){\n        res$where.ctree <- table(nn)\n      }else{\n        res$where.ctree <- sapply(split(nn, nn$var),table)\n      }\n\n    }\n\n\n    if(any(methods==c(\"rpart\"))){\n      var.count <- matrix(NA,n.rep,length(preds))\n      colnames(var.count) <- preds\n      where.rpart <- list()\n\n      for(i in 1:n.rep){\n        hh <- out[[i]]$rpart.splits\n        tab <- table(hh[,1])\n        where.rpart[[i]] <- hh\n\n        for(j in 1:length(preds)){\n          var.count[i,preds[j]] <- tab[preds[j]]\n          if(is.na(var.count[i,preds[j]]==TRUE)) var.count[i,preds[j]] <- 0\n        }\n      }\n\n      counts.mean[\"rpart\",] <- colMeans(var.count)\n      counts.var[\"rpart\",] <- round(matrixStats::colVars(var.count),2)\n      nn <- plyr::ldply(where.rpart)\n      if(length(unique(nn[,1])) == 1){\n        res$where.rpart <- table(nn)\n      }else{\n        res$where.rpart <- sapply(split(nn, nn$var),table)\n      }\n\n    }\n\n\n\n    if(any(methods==c(\"evtree\"))){\n      var.count <- matrix(NA,n.rep,length(preds))\n      colnames(var.count) <- preds\n      where.evtree <- list()\n\n      for(i in 1:n.rep){\n        hh <- out[[i]]$evtree.splits\n        tab <- table(hh[,1])\n        where.evtree[[i]] <- hh\n\n        for(j in 1:length(preds)){\n          var.count[i,preds[j]] <- tab[preds[j]]\n          if(is.na(var.count[i,preds[j]]==TRUE)) var.count[i,preds[j]] <- 0\n        }\n      }\n\n      counts.mean[\"evtree\",] <- colMeans(var.count)\n      counts.var[\"evtree\",] <- round(matrixStats::colVars(var.count),2)\n      nn <- plyr::ldply(where.evtree)\n      if(length(unique(nn[,1])) == 1){\n        res$where.evtree <- table(nn)\n      }else{\n        res$where.evtree <- sapply(split(nn, nn$var),table)\n      }\n    }\n\n\n\n    res$counts.mean <- counts.mean\n    res$counts.var <- counts.var\n    res$means <- round(ret.mean,3)\n    res$variances <- round(ret.var,3)\n    res\n  }else{\n\n    stop(\"Curently not working\")\n    methods2=methods\n    if(any(methods2==c(\"lm\",\"rf\"))) stop(\"only decision tree methods can be used with stable learner\")\n\n    trees <- dtree(formula,data,methods=methods2,samp.method,\n          tuneLength,subset,perc.sub,prune,weights,verbose)\n\n\n    if(any(methods2==c(\"rpart\"))){\n      formula2 <- terms(formula,data=data)\n      tree1 <- rpart(formula(formula2),data)\n      tree2 <- prune(tree1,cp=as.numeric(trees$rpart.train$bestTune))\n      res$rpart <- stablelearner::stabletree(tree2,data=data,B=100)\n    }\n\n    if(any(methods2==c(\"ctree\"))){\n     # formula2 <- terms(formula,data=data)\n      #val = 1-as.numeric(trees$ctree.train$bestTune)\n      #ctrl=ctree_control()#(mincriterion=val)\n     # treet <- partykit::ctree(formula(formula2),data=data)#,control=ctrl)\n     # res$ctree <- stablelearner::stabletree(treet,data=data,formula=formula(formula2))\n      tt = train(default ~ ., data=Default,method=\"ctree\")\n      tree1 <- partykit::ctree(default ~ income, data=Default,\n                               control=ctree_control(mincriterion=as.numeric(tt$bestTune)))\n     stablelearner::stabletree(tree1)\n    }\n\n    if(any(methods2==c(\"evtree\"))){\n      tree <- dtree(formula,data,methods=\"evtree\",samp.method,\n                    tuneLength,subset,perc.sub,prune,weights,verbose)$evtree.out\n      res$evtree <- stablelearner::stabletree(tree,data=data,B=100)\n    }\n\n\n  }\n\n\n\nreturn(res)\n\n\n}\n",
    "created" : 1490195270484.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2554821162",
    "id" : "D49B51AC",
    "lastKnownWriteTime" : 1490302381,
    "last_content_update" : 1490302381918,
    "path" : "~/GitHub/dtree/R/stable.R",
    "project_path" : "R/stable.R",
    "properties" : {
    },
    "relative_order" : 8,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}